# Vision Transformers

## Transformers in Vision: A Survey

二话不说先谷歌 [`vision transformer survey`](https://www.google.com/search?q=vision%20transformer%20survey)，果然找到 2021 年一篇引用 1796 次<f>（截至 2024-03-06）</f>的文章：

::: tip [2101.01169] Transformers in Vision: A Survey
- [abstract](https://arxiv.org/abs/2101.01169)・[ar5iv](https://ar5iv.labs.arxiv.org/html/2101.01169)・[pdf (30页)](https://arxiv.org/pdf/2101.01169.pdf)
- Salman Khan 等人，提交于 **2021-01-04**，更新于 2022-01-19.

<details open>
<summary><b>摘要</b> <f>(GLM-4 辅助翻译)</f></summary>

> ……Transformer 的主要优点：
> 1. **能够建立输入序列元素之间的长距离依赖关系**，并且与循环网络<f>（例如 LSTM）</f>相比，**支持序列的并行处理**。
> 2. 不同于卷积网络，Transformer **在设计中所需的归纳偏置较少**，并且**天然适合作为集合函数**。
> 3. ……处理**多模态**……，并且在非常大的容量网络和海量数据集上展示了出色的**可扩展性**。
> 
> ……本调查……对计算机视觉领域中 Transformer 模型的全面概述。
> 1. ……基本概念，即**自注意力**、**大规模预训练**和**双向编码**。
> 2. ……在视觉领域的广泛应用，包括流行的识别任务（例如图像分类、目标检测、动作识别和分割）、生成建模、多模态任务（例如视觉 - 问题回答、视觉推理和视觉定位）、视频处理（例如活动识别、视频预测）、低级视觉（例如图像超分辨率、图像增强和着色）以及 3D 分析（例如点云分类和分割）。
> 3. ……比较了流行技术在架构设计和实验价值方面的各自优势和局限性。
> 4. ……开放性研究方向……和可能……的展望。
</details>
:::
